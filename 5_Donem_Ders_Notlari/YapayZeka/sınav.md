# YZT 2024 Final Sınavı Detaylı Çözüm

## 1. Boşluk Doldurma Sorusu

### Sorular ve Cevaplar:

- **a)** Toplamda \( n \) tane değişken barındıran bir Bayes ağında \( X_1, X_2, \ldots, X_k \) değişkenlerinin ataları bulunmuyorsa, **bu değişkenlerin bağımsız olduğu anlaşılır**.

  **Açıklama:** Bayes ağında bağımsızlıklar, değişkenlerin atalarıyla kurulan doğrusal olmayan ilişkilerle tanımlanır. Ataları olmayan değişkenler bağımsız olarak kabul edilir.

- **b)** Çapraz doğrulamada veri kümesi genelde **eğitim, test ve doğrulama** olarak üçe bölünür.

  **Açıklama:** Bu ayrım, modelin aşırı uyum veya yetersiz öğrenme problemleri yaşamaması için önemlidir.

- **c)** Bir modelin veri kümesine az uyumu halinde **yüksek sapma (bias)**, aşırı uyumu halinde ise **yüksek değişim (varyans)** oluşur.

  **Açıklama:** Sapma, modelin yetersiz öğrenmesine; varyans ise modelin aşırı öğrenmesine işaret eder.

- **d)** AdaBoost sınıflandırıcıda bir test örneği, **tüm sınıflandırıcıların verdiği etiketlerin çoğunluğuna göre** sınıflandırılır.

  **Açıklama:** AdaBoost, birden fazla zayıf sınıflandırıcının toplu çalışmasıyla güçlü bir model oluşturur.

- **e)** ROC eğrisi, **değişen eşik değerlerinde yanlış pozitif oranına karşılık doğru pozitif oranını çizdirir**.

  **Açıklama:** ROC eğrisi, bir modelin performansının farklı eşik değerlerindeki dengesini ölçer.

- **f)** İkili karar ağacı düğümlerinde **bir özellik ve değer çifti** yer alır.

  **Açıklama:** Karar ağaçları, özelliklerin belirli değerlerine göre döküm yapar.

- **g)** Entropi, eldeki bir veri kümesinin **karmaşıklığını ölçmeye yardımcı olur**.

  **Açıklama:** Daha düzgün dağılmış veriler daha düşük entropiye sahiptir.

- **h)** Budama, **karar ağaçlarında aşırı uyumu önlemenin bir yoludur**.

  **Açıklama:** Aşırı büyümüş bir karar ağacı, gereksiz düğümler barındırarak varyansa neden olur.

- **i)** Tek bir yapay sinir hücresi, **XOR veya XNOR problemlerini çözemez**.

  **Açıklama:** XOR, lineer olarak ayrılamaz bir problemdir.

- **j)** Çok katmanlı yapay sinir ağlarıyla **iki boyutta çıkıntı (bump) benzeri karar sınırlarını öğrenebilmek için üç veya daha fazla katmana ihtiyaç vardır**.

  **Açıklama:** Daha fazla katman, daha karmaşık karar sınırları oluşturabilir.

- **k)** K-en yakın komşular algoritmasında bir veri örneğinin komşuları, **mesafe ölçülerek belirlenir**.

  **Açıklama:** Mesafe fonksiyonları (Euclidean vb.) KNN algoritmasının temelindedir.

- **l)** **Sarmalayıcı bir özellik seçim algoritması PCA, bir özellik çıkartım algoritmasıdır**.

  **Açıklama:** PCA, var olan özelliklerden yeni boyutlar oluşturarak veriyi azaltır.

---

