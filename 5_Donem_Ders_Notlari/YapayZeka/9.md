# Geçici Olasılıksal Akıl Yürütme ve Gizli Markov Modelleri

## Geçici Olasılıksal Akıl Yürütme (Temporal Probabilistic Reasoning)

### Tanım
Geçici olasılıksal akıl yürütme, zaman çizgisi boyunca belirsizliklerin takibini ve tahmin edilmesini konu alan bir yaklaşımdır. Zaman değişkenleri ve gözlem değişkenlerinin zamana yayılan bir yapıda tekrarlandığı bir model kullanır. Markov varsayımları ve durağanlık şartları çerçevesinde geçiş ve gözlem modelleri tanımlanır.

### Kullanım Alanları
- **Diyabet yönetimi:** Kan şekeri seviyelerinin takip edilmesi ve olası gelecekteki dalgalanmaların tahmini.
- **Araç arızası teşhisi:** Araç performansının zamana bağlı olarak takip edilmesi ve potansiyel arızaların öngörülmesi.

### Temel Varsayımlar
- **Markov Varsayımı:** Geçerli bir durumun olasılığı yalnızca bir önceki duruma bağlıdır:
  \[
  P(Q_t | Q_{0:t-1}) = P(Q_t | Q_{t-1})
  \]
- **Durağanlık (Stationarity):** Zamanla geçiş ve gözlem modelleri değişmez.

---

## Gizli Markov Modelleri (Hidden Markov Models - HMMs)

### Tanım
Gizli Markov modelleri, bir dizi gözlemden hareketle gizli bir durum dizisinin olasılığını tahmin etmek üzere kullanılan probabilistik bir modeldir. 

### Bileşenler
1. **Durumlar (States):** Gizli değişkenlerdir ve gözlemlere neden olan kaynakları temsil eder. 
2. **Gözlemler (Observations):** Model tarafından gözlemlenebilen verilerdir.
3. **Geçiş Olasılıkları (Transition Probabilities):** Bir durumdan başka bir duruma geçişin olasılığıdır.
4. **Gözlem Olasılıkları (Emission Probabilities):** Bir durumun belli bir gözlem üretme olasılığıdır.
5. **Başlangıç Olasılıkları (Initial Probabilities):** Modelin hangi durumla başlayacağına dair olasılıkları temsil eder.

### Kullanım Alanları
- **Konuşma Tanıma:** Ses sinyallerinin kelime dizilerine dönüştürülmesi.
- **Metin Düzeltme:** Hatalı metinlerin doğrulanması.
- **Dil İşleme:** Kelime gruplarının etiketlenmesi (ad, fiil, zamir vb.).

### Markov Zincirleri
- **Birinci Dereceden Markov Zinciri:** Geçerli durum, yalnızca bir önceki duruma bağlıdır.
- **İkinci Dereceden Markov Zinciri:** Geçerli durum, iki önceki duruma bağlıdır:
  \[
  P(Q_t | Q_{0:t-1}) = P(Q_t | Q_{t-1}, Q_{t-2})
  \]

---

## HMM Örneği: Dondurma ve Hava Durumu

### Senaryo
Feyza'nın bir yaz boyunca günlük yediği dondurma sayısı (örneğin 1, 2 veya 3 dondurma) kaydedilmiştir. Bu gözlemlerden hareketle, o günün hava durumunun "sıcak" (H) veya "soğuk" (C) olup olmadığı tahmin edilmek istenir.

### Amaç
- **Girdiler:** Gözlemler (dondurma sayısı).
- **Çıktılar:** Gizli durumlar (hava durumu).
- **Problem:** Gözlemlere dayanarak gizli durum dizisini tahmin etmek.

---

## HMM Algoritmaları

### İleri Algoritma (Forward Algorithm)
- Gözlem dizisinin toplam olasılığını hesaplar.
- Dinamik programlama teknikleri kullanarak karmaşıklığı azaltır.
- Karmaşıklık: \( O(N^2 T) \).

### Viterbi Algoritması
- En olası gizli durum dizisini bulur.
- Her adımda maksimum olasılık yolunu izler.
- **Backtrace (Geri Takip):** En iyi yol, gizli durumlar boyunca geriye dönülerek bulunur.

### Baum-Welch Algoritması (Forward-Backward)
- Parametreleri öğrenmek için kullanılır.
- Expectation-Maximization (EM) algoritmasının bir özel halidir.
- İteratif olarak geçiş ve gözlem olasılıklarını iyileştirir.

---

## Konuşma Tanıma ve HMM

### Zorluklar
- İnsan konuşmasındaki çeşitlilik (hız, tımbre, aksan).
- Arka plan gürültüsü ve seslerin birbiriyle karışması.

### Telefonlar (Phones)
- Tüm insan konuşması 40-50 temel "telefon" birimine ayrılabilir.
- Telefonlar sesin oluştuğu artikülasyon hareketleriyle belirlenir (dil, dişler, dudaklar vb.).

### Dil Modeli
- **Bayes Kuralı:**
  \[
  P(Words|Signal) = P(Signal|Words) \cdot P(Words)
  \]
- Konuşma sinyalini gizli kelime dizilerine dönüştürmek için akustik ve dil modelleri kullanılır.

---

